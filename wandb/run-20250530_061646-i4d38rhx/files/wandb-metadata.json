{
  "os": "Linux-5.4.0-150-generic-x86_64-with-glibc2.31",
  "python": "CPython 3.10.13",
  "startedAt": "2025-05-30T06:16:46.141616Z",
  "args": [
    "--task_name",
    "long_term_forecast",
    "--is_training",
    "1",
    "--root_path",
    "./dataset/Nasdaq100/",
    "--data_path",
    "nasdaq100.csv",
    "--model_id",
    "nasdaq100_512_96",
    "--model",
    "TimeLLM",
    "--data",
    "nasdaq100",
    "--features",
    "M",
    "--target",
    "Close",
    "--seq_len",
    "512",
    "--label_len",
    "48",
    "--pred_len",
    "96",
    "--factor",
    "3",
    "--enc_in",
    "5",
    "--dec_in",
    "5",
    "--c_out",
    "5",
    "--des",
    "Exp",
    "--itr",
    "1",
    "--d_model",
    "32",
    "--d_ff",
    "128",
    "--batch_size",
    "4",
    "--learning_rate",
    "0.01",
    "--llm_layers",
    "8",
    "--train_epochs",
    "10",
    "--model_comment",
    "TimeLLM-Money",
    "--use_wandb",
    "--wandb_iter",
    "1",
    "--exp_name",
    "TimeLLM-Money",
    "--project_name",
    "TimeLLM",
    "--entity",
    "beaver22-seoul-national-university"
  ],
  "program": "/container/volume_data/Time-LLM/run_main.py",
  "codePath": "run_main.py",
  "git": {
    "remote": "https://github.com/beaver-22/Time-LLM.git",
    "commit": "02ee1b8f6043090c7a417f0cbb64cbf753895175"
  },
  "email": "asap3090@gmail.com",
  "root": "/container/volume_data/Time-LLM",
  "host": "301a64c6cf66",
  "executable": "/opt/conda/bin/python",
  "codePathLocal": "run_main.py",
  "cpu_count": 4,
  "cpu_count_logical": 8,
  "gpu": "NVIDIA GeForce RTX 2080 Ti",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "3936290357248",
      "used": "60916019200"
    }
  },
  "memory": {
    "total": "67340320768"
  },
  "cpu": {
    "count": 4,
    "countLogical": 8
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 2080 Ti",
      "memoryTotal": "11811160064",
      "cudaCores": 4352,
      "architecture": "Turing"
    }
  ],
  "cudaVersion": "12.1"
}